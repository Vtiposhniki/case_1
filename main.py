import pandas as pd
import logging
from pathlib import Path

from src.data_preprocessing import DataPreprocessor
from src.feature_engineering import FeatureEngineering
from src.model import ModelManager
from src.push_generator import generate_push_notifications, generate_push_report
from src.scoring_system import BankingPersonalizationSystem, create_scoring_dashboard
from src.utils import save_json

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('reports/pipeline.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π"""

    try:
        logger.info("–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –±–∞–Ω–∫–æ–≤—Å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—Ç—á–µ—Ç–æ–≤
        Path("reports").mkdir(exist_ok=True)
        Path("reports/figures").mkdir(exist_ok=True)

        # 1. Data Preprocessing
        print("üöÄ Step 1: Data Preprocessing...")
        logger.info("–ù–∞—á–∞–ª–æ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

        preprocessor = DataPreprocessor()
        preprocessor.export_all_data()

        logger.info("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

        # 2. Feature Engineering
        print("üöÄ Step 2: Feature Engineering...")
        logger.info("–ù–∞—á–∞–ª–æ –∏–Ω–∂–µ–Ω–µ—Ä–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")

        fe = FeatureEngineering()
        if not fe.create_features():
            raise RuntimeError("‚ùå Feature engineering failed")
        fe.save_features()

        logger.info("–ò–Ω–∂–µ–Ω–µ—Ä–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        print("üìä Loading processed data...")
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

        profiles_df = pd.read_csv("data/processed/clients.csv")
        transactions_df = pd.read_csv("data/processed/combined_transactions.csv")
        transfers_df = pd.read_csv("data/processed/combined_transfers.csv")

        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {len(profiles_df)} –∫–ª–∏–µ–Ω—Ç–æ–≤, "
                    f"{len(transactions_df)} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, "
                    f"{len(transfers_df)} –ø–µ—Ä–µ–≤–æ–¥–æ–≤")

        # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        if profiles_df.empty:
            raise ValueError("–§–∞–π–ª –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø—É—Å—Ç")
        if transactions_df.empty:
            logger.warning("–§–∞–π–ª —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø—É—Å—Ç")
        if transfers_df.empty:
            logger.warning("–§–∞–π–ª –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –ø—É—Å—Ç")

        # 3. Model Training / Loading
        print("üöÄ Step 3: Training or Loading Model...")
        logger.info("–û–±—É—á–µ–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏")

        model_manager = ModelManager()
        if not model_manager.model_path.exists():
            logger.info("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –Ω–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ")
            model_manager.train(fe.features_df)
        else:
            logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏")
            model_manager.load()

        # 4. Client Scoring and Personalization
        print("üöÄ Step 4: Client Scoring...")
        logger.info("–ù–∞—á–∞–ª–æ —Å–∫–æ—Ä–∏–Ω–≥–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤")

        scoring_system = BankingPersonalizationSystem()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤ (–∏—Å–ø—Ä–∞–≤–ª—è–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ)
        offers_df = scoring_system.process_all_clients(profiles_df, transactions_df, transfers_df)

        if offers_df.empty:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –∫–ª–∏–µ–Ω—Ç–æ–≤")

        logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(offers_df)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")

        # 5. Save Results and Generate Analytics
        print("üöÄ Step 5: Generating Analytics...")
        logger.info("–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏")

        scoring_system.save_results(offers_df)

        stats = scoring_system.generate_analytics_report(offers_df)
        save_json(stats, "reports/scoring_summary.json")

        logger.info("–ë–∞–∑–æ–≤–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

        # 6. Push Notifications
        print("üöÄ Step 6: Generating Push Notifications...")
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º DataFrame –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è push_generator
        offers_dict = (
            offers_df.groupby("client_code")
            .apply(lambda g: g.to_dict("records"))
            .to_dict()
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        push_notifications = generate_push_notifications(
            offers_dict,
            fe.features_df,
            "reports/push_notifications.json"
        )

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç –ø–æ –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è–º
        push_report = generate_push_report(
            push_notifications,
            "reports/push_report.json"
        )

        logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {len(push_notifications)} –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π")
        logger.info(f"–ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º: {push_report['summary']['compliance_rate']}%")

        # 7. Dashboard Creation
        print("üöÄ Step 7: Creating Dashboard...")
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞")

        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∞—à–±–æ—Ä–¥ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            create_scoring_dashboard(
                offers_dict,  # –°–ª–æ–≤–∞—Ä—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                stats,  # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–∑ analytics report
                fe.features_df,  # –î–∞–Ω–Ω—ã–µ –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö
                show=True
            )
            logger.info("–î–∞—à–±–æ—Ä–¥ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–∞—à–±–æ—Ä–¥–∞: {e}")
            print(f"‚ö†Ô∏è Dashboard creation failed: {e}")
            print("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –¥–∞—à–±–æ—Ä–¥–∞...")

        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–≤–æ–¥–∫–∞
        print("\n‚úÖ Pipeline finished successfully!")
        print("\nüìã Results Summary:")
        print(f"   ‚Ä¢ Processed clients: {len(profiles_df)}")
        print(f"   ‚Ä¢ Generated offers: {len(offers_df)}")
        print(f"   ‚Ä¢ Push notifications: {len(push_notifications)}")
        print(f"   ‚Ä¢ Push compliance rate: {push_report['summary']['compliance_rate']}%")
        print(f"   ‚Ä¢ Most recommended product: {stats.get('most_recommended_product', 'N/A')}")

        print("\nüìÅ Output files:")
        print("   ‚Ä¢ reports/client_recommendations.csv")
        print("   ‚Ä¢ reports/scoring_summary.json")
        print("   ‚Ä¢ reports/push_notifications.json")
        print("   ‚Ä¢ reports/push_report.json")
        print("   ‚Ä¢ reports/figures/scoring_dashboard.png")
        print("   ‚Ä¢ reports/pipeline.log")

        logger.info("–ü–∞–π–ø–ª–∞–π–Ω —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω")

        return {
            'offers_df': offers_df,
            'push_notifications': push_notifications,
            'stats': stats,
            'push_report': push_report
        }

    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞: {e}")
        print(f"‚ùå Pipeline failed: {e}")
        raise


def validate_pipeline_results(results: dict) -> bool:
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞"""

    validation_issues = []

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    if results['offers_df'].empty:
        validation_issues.append("–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    if not results['push_notifications']:
        validation_issues.append("–ù–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
    push_compliance = results['push_report']['summary']['compliance_rate']
    if push_compliance < 80:
        validation_issues.append(f"–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—É—à-—É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π: {push_compliance}%")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤
    product_count = len(results['stats'].get('product_distribution', {}))
    if product_count < 3:
        validation_issues.append(f"–ú–∞–ª–æ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {product_count}")

    if validation_issues:
        logger.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–∞—á–µ—Å—Ç–≤–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for issue in validation_issues:
            logger.warning(f"  - {issue}")
        return False

    logger.info("–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    return True


def run_pipeline_with_validation():
    """–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""

    results = main()

    print("\nüîç Validating results...")
    is_valid = validate_pipeline_results(results)

    if is_valid:
        print("‚úÖ All validation checks passed!")
    else:
        print("‚ö†Ô∏è Some quality issues detected. Check logs for details.")

    return results, is_valid


if __name__ == "__main__":
    try:
        results, is_valid = run_pipeline_with_validation()
    except Exception as e:
        print(f"üí• Critical error: {e}")
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)